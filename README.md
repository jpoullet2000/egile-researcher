# Egile Researcher

üî¨ **AI-Powered Research Automation with MCP Integration**

Egile Researcher is an intelligent research assistant that helps researchers, academics, and knowledge workers stay up-to-date with the latest publications in their field. It provides automated summarization, analysis, and insights from recent academic papers and research publications.

**üÜï Now featuring:**
- **MCP Server Architecture** - Expose research tools as standardized services
- **AI-Powered Planning** - Intelligent agents that plan and execute multi-step research workflows
- **Dynamic Tool Discovery** - Agents that adapt to available research capabilities
- **Multi-Client Support** - Integration with Claude Desktop, custom applications, and more

## üèóÔ∏è Architecture Options

Egile Researcher offers multiple ways to access research capabilities:

### 1. üß† AI Research Agent (Recommended)
Intelligent agent that uses LLM reasoning to plan and execute complex research tasks:

```python
from egile_researcher import ai_research

# AI automatically plans and executes multi-step research
result = await ai_research("Find recent papers about quantum machine learning and analyze trends")
```

### 2. üîß Traditional Research Agent
Direct Python API for programmatic access:

```python
from egile_researcher import ResearchAgent

agent = ResearchAgent()
papers = await agent.search_papers("machine learning")
```

### 3. üåê MCP Server
Standardized server exposing research tools for any MCP-compatible client:

```bash
# Start MCP server
python -m egile_researcher.server
```

### 4. üîå MCP Client Integration
Use with Claude Desktop, VS Code, or custom applications.

## üöÄ Features

### üß† AI-Powered Intelligence
- **Intelligent Planning**: AI agents that create optimal execution plans for complex research tasks
- **Dynamic Tool Discovery**: Agents automatically discover and use available research tools
- **Multi-Step Reasoning**: Chain research operations intelligently based on context
- **Fallback Mechanisms**: Graceful degradation when AI services are unavailable

### üî¨ Core Research Capabilities
- **Publication Discovery**: Find recent papers from arXiv, PubMed, Google Scholar, and other sources
- **Intelligent Summarization**: AI-powered summaries extracting key findings and methodologies
- **Research Analysis**: Deep analysis of research trends, citation patterns, and emerging topics
- **Comparative Studies**: Compare multiple papers and identify relationships between research works
- **Citation Tracking**: Monitor citations and impact of specific papers or research areas
- **Topic Clustering**: Group related publications and identify research themes

### üåê MCP Integration
- **MCP Server**: Expose research capabilities as standardized MCP tools
- **Claude Desktop Integration**: Use research tools directly in Claude Desktop
- **Multi-Client Support**: Compatible with any MCP client application
- **Tool Interoperability**: Research tools can be combined with other MCP services

### üõ†Ô∏è Available MCP Tools
- `search_papers` - Search for research papers across multiple sources
- `summarize_paper` - Generate intelligent summaries of research papers  
- `analyze_trends` - Analyze research trends for specific topics
- `compare_papers` - Compare multiple research papers
- `generate_research_report` - Generate comprehensive research reports
- `search_and_summarize` - Search for papers and generate summaries in one step
- `analyze_topic_comprehensively` - Perform comprehensive analysis of research topics

## üì¶ Installation

### Using Poetry (Recommended)
```bash
# Clone the repository
git clone <repository-url>
cd egile-researcher

# Install with Poetry
poetry install

# Activate the environment
poetry shell
```

### Using pip
```bash
pip install egile-researcher
```

## üõ†Ô∏è Configuration

### Environment Variables
Create a `.env` file with your configuration:

```env
# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_OPENAI_DEFAULT_MODEL=gpt-4.1-mini
AZURE_USE_MANAGED_IDENTITY=false

# Research Database APIs (optional)
ARXIV_API_KEY=your_arxiv_key
PUBMED_API_KEY=your_pubmed_key
SEMANTIC_SCHOLAR_API_KEY=your_semantic_scholar_key
```

## üìö Quick Start

### üß† AI Research Agent (Simplest)

The AI Research Agent is the easiest way to get started. It automatically plans and executes complex research tasks:

```python
import asyncio
from egile_researcher import ai_research

async def main():
    # AI automatically plans and executes research workflow
    result = await ai_research("Find recent papers about transformer models in NLP")
    
    # View the execution plan
    print(f"AI created {len(result['plan'])} step plan:")
    for step in result['plan']:
        print(f"  {step['step']}: {step['description']}")
    
    # Check results
    summary = result['summary']
    print(f"‚úÖ {summary['successful_steps']}/{summary['total_steps']} steps completed")

if __name__ == "__main__":
    asyncio.run(main())
```

### ü§ñ Advanced AI Agent Usage

For more control over the AI agent:

```python
from egile_researcher import AIResearchAgent

async def advanced_research():
    async with AIResearchAgent() as agent:
        # Agent automatically discovers available tools
        print(f"Available tools: {list(agent.available_tools.keys())}")
        
        # Perform intelligent research
        result = await agent.research("Research quantum computing trends and provide analysis")
        
        # Access detailed execution results
        for step in result['execution_results']:
            if step['success']:
                print(f"‚úÖ Step {step['step']}: {step['description']}")
            else:
                print(f"‚ùå Step {step['step']}: {step['error']}")
        
        # Or call specific tools manually
        papers = await agent.call_tool("search_papers", {
            "query": "machine learning interpretability",
            "max_results": 5
        })

asyncio.run(advanced_research())
```

### üîß Traditional Agent Usage

Direct API access for programmatic control:

```python
import asyncio
from egile_researcher import ResearchAgent
from egile_researcher.config import ResearchAgentConfig, AzureOpenAIConfig

async def traditional_usage():
    # Configure the research agent
    openai_config = AzureOpenAIConfig.from_environment()
    agent_config = ResearchAgentConfig(
        openai_config=openai_config,
        research_areas=["machine learning", "artificial intelligence"],
        max_papers_per_search=10
    )
    
    # Initialize the agent
    agent = ResearchAgent(agent_config)
    
    # Search for recent papers
    papers = await agent.search_papers(
        query="large language models",
        days_back=7,
        max_results=5
    )
    
    # Summarize papers
    for paper in papers:
        summary = await agent.summarize_paper(paper)
        print(f"Title: {paper['title']}")
        print(f"Summary: {summary['summary']}")
        print(f"Key Findings: {summary['key_findings']}")
        print("-" * 50)
    
    await agent.close()

asyncio.run(traditional_usage())
```

### üåê MCP Server Usage

#### Starting the MCP Server

```bash
# Start the MCP server
python -m egile_researcher.server
```

#### Claude Desktop Integration

Add to your Claude Desktop configuration (`claude_desktop_config.json`):

```json
{
  "mcpServers": {
    "egile-researcher": {
      "command": "python",
      "args": ["-m", "egile_researcher.server"],
      "env": {
        "AZURE_OPENAI_API_KEY": "your-api-key",
        "AZURE_OPENAI_ENDPOINT": "your-endpoint"
      }
    }
  }
}
```

#### Custom MCP Client

```python
from mcp.client.stdio import StdioServerParameters, stdio_client
from mcp.client.session import ClientSession

async def use_mcp_client():
    # Configure server parameters with proper command splitting
    server_params = StdioServerParameters(
        command="python",
        args=["-m", "egile_researcher.server"]
    )
    
    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()
            
            # List available tools
            tools = await session.list_tools()
            print(f"Available tools: {[tool.name for tool in tools.tools]}")
            
            # Call a research tool (using correct format)
            result = await session.call_tool(
                "search_papers",
                {"query": "AI research", "max_results": 5}
            )
            print(f"Search results: {result.content}")

asyncio.run(use_mcp_client())
```

### üéØ Advanced Research Workflows

```python
# AI agent can handle complex multi-step research tasks
result = await ai_research("""
    Research the latest developments in quantum machine learning, 
    analyze trends over the past year, and provide insights on 
    future research directions
""")

# Traditional agent for specific operations
trends = await agent.analyze_trends(
    topic="transformer architectures",
    time_period="last_month"
)

comparison = await agent.compare_papers([paper1, paper2, paper3])

report = await agent.generate_research_report(
    topic="recent advances in NLP",
    include_visualizations=True
)
```

## üèóÔ∏è Architecture

### Core Components

- **AI Research Agent** (`AIResearchAgent`): Intelligent agent using LLM reasoning for research planning
- **Traditional Research Agent** (`ResearchAgent`): Direct API for programmatic research tasks
- **MCP Server** (`server.py`): Exposes research capabilities as MCP tools
- **MCP Client** (`mcp_client.py`): Python client for MCP server integration
- **Research Tools** (`tools/`): Individual research tool implementations
- **Configuration System** (`config.py`): Type-safe configuration management

### AI Agent Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     AI Research Agent                       ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üß† LLM Planning Engine                                     ‚îÇ
‚îÇ  ‚îú‚îÄ Task Analysis                                          ‚îÇ
‚îÇ  ‚îú‚îÄ Tool Selection                                         ‚îÇ
‚îÇ  ‚îú‚îÄ Multi-step Planning                                    ‚îÇ
‚îÇ  ‚îî‚îÄ Context Enhancement                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üîå MCP Client Interface                                   ‚îÇ
‚îÇ  ‚îú‚îÄ Dynamic Tool Discovery                                 ‚îÇ
‚îÇ  ‚îú‚îÄ Tool Execution                                         ‚îÇ
‚îÇ  ‚îî‚îÄ Session Management                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº MCP Protocol
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      MCP Server                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üõ†Ô∏è Research Tools                                         ‚îÇ
‚îÇ  ‚îú‚îÄ search_papers                                          ‚îÇ
‚îÇ  ‚îú‚îÄ summarize_paper                                        ‚îÇ
‚îÇ  ‚îú‚îÄ analyze_trends                                         ‚îÇ
‚îÇ  ‚îú‚îÄ generate_insights                                      ‚îÇ
‚îÇ  ‚îî‚îÄ create_bibliography                                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  üî¨ Research Agent Core                                    ‚îÇ
‚îÇ  ‚îú‚îÄ Publication Fetchers                                   ‚îÇ
‚îÇ  ‚îú‚îÄ Content Processors                                     ‚îÇ
‚îÇ  ‚îú‚îÄ AI Summarizers                                         ‚îÇ
‚îÇ  ‚îî‚îÄ Trend Analyzers                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### MCP Integration Benefits

1. **Modularity**: Research tools as discrete, reusable services
2. **Interoperability**: Compatible with any MCP client
3. **Scalability**: Server handles multiple concurrent clients
4. **Intelligence**: AI agents can dynamically combine tools
5. **Flexibility**: Choose the right level of automation for your needs

## üß™ Testing & Examples

### Run the AI Agent Demo

```bash
# Test AI-powered planning capabilities
python tmp/demo_planning.py

# Test basic AI agent functionality  
python tmp/test_basic.py

# Test AI agent with MCP server integration
python tmp/test_ai_agent.py
```

### Example AI Planning Output

```
ü§ñ AI Research Agent Planning Demo
==================================================
‚úÖ AI Agent created

üß† Testing AI-powered planning...
‚úÖ AI plan created with 3 steps:
  ‚Ä¢ Step 1: Search for recent papers about transformer models published in the last year
  ‚Ä¢ Step 2: Generate summaries for the found papers to provide concise overviews  
  ‚Ä¢ Step 3: Analyze research trends related to transformer models over the past year
```

### MCP Server Testing

```bash
# Start MCP server in background
python -m egile_researcher.server &

# Test MCP client functionality
python tmp/test_mcp_server.py

# Stop server
pkill -f "egile_researcher.server"
```

## üîß Development

### Setting up Development Environment

```bash
# Clone and setup
git clone <repository-url>
cd egile-researcher
poetry install --with dev

# Run tests
poetry run pytest

# Test AI agent capabilities
python tmp/demo_planning.py

# Format code
poetry run black .
poetry run isort .

# Type checking
poetry run mypy egile_researcher/
```

### Key Development Files

- `egile_researcher/ai_agent.py` - AI-powered research agent
- `egile_researcher/server.py` - MCP server implementation
- `egile_researcher/agent.py` - Traditional research agent
- `egile_researcher/tools/` - Individual research tools
- `tmp/demo_*.py` - Example and test scripts

## üìñ Documentation

- [MCP Setup Guide](MCP_SETUP_NEW.md) - Comprehensive MCP integration guide
- [API Reference](docs/api.md) - Complete API documentation
- [Configuration Guide](docs/configuration.md) - Configuration options
- [Research Sources](docs/sources.md) - Supported research databases
- [Examples](examples/) - Usage examples and tutorials

## üöÄ What's New

### v0.2.0 - MCP Integration & AI Agents
- **üß† AI Research Agent**: Intelligent planning and execution of research tasks
- **üåê MCP Server**: Standardized research tools accessible via MCP protocol
- **üîå Claude Desktop Integration**: Use research tools directly in Claude Desktop
- **üìã Smart Planning**: LLM-powered planning with fallback heuristics
- **üîÑ Dynamic Tool Discovery**: Agents adapt to available research capabilities

### Migration from v0.1.x

The traditional `ResearchAgent` API remains unchanged. New features:

```python
# Old way (still works)
agent = ResearchAgent()
papers = await agent.search_papers("ML")

# New AI-powered way  
result = await ai_research("Find and analyze recent ML papers")

# New MCP integration
# Start server: python -m egile_researcher.server
# Use with Claude Desktop or custom MCP clients
```

## ü§ù Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üîó Related Projects

- [MCP Protocol](https://modelcontextprotocol.io/) - Model Context Protocol specification
- [FastMCP](https://github.com/jlowin/fastmcp) - Fast MCP server framework
- [Claude Desktop](https://claude.ai/download) - AI assistant with MCP support

## üéØ Use Cases

### üìö Academic Researchers
- Track latest developments in your field
- Automated literature reviews
- Research trend analysis
- Citation impact tracking

### üè¢ R&D Teams
- Competitive intelligence
- Technology trend monitoring
- Patent landscape analysis
- Innovation opportunity identification

### ü§ñ AI Applications
- Research tool integration via MCP
- Automated research assistants
- Knowledge base updates
- Content generation pipelines

### üî¨ Research Institutions
- Departmental research dashboards
- Grant application support
- Collaboration opportunity identification
- Research impact assessment

---

**Stay ahead in research with Egile Researcher - where AI meets academic excellence.** üéì‚ú®

## ‚úÖ Current Status

**The MCP refactoring has been successfully completed!** üéâ

### Tested & Working Features
- ‚úÖ **MCP Server**: Starts correctly and exposes 7 research tools
- ‚úÖ **AI Agent Connection**: Successfully connects to MCP server and discovers tools
- ‚úÖ **Tool Discovery**: All 7 tools properly discovered with descriptions
- ‚úÖ **AI Planning**: LLM-powered planning working with OpenAI integration
- ‚úÖ **Fallback Planning**: Heuristic planning works when LLM unavailable
- ‚úÖ **Multi-Step Workflows**: Intelligent agents can plan complex research tasks

### Architecture Transformation Complete
- ‚úÖ Migrated from monolithic agent to MCP server architecture
- ‚úÖ AI agents with dynamic tool discovery
- ‚úÖ Traditional API maintained for backward compatibility
- ‚úÖ Full documentation and examples updated

### Ready for Production
The system is ready for use in all supported modes: AI agents, traditional agents, MCP server, and client integrations.

---
